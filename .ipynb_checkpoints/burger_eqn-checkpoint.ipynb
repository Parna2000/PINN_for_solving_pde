{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16131054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07be5625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn_solver import PINNSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43ea178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn_neural_net import PINN_NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d5fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE='float32'\n",
    "tf.keras.backend.set_floatx(DTYPE)\n",
    "\n",
    "# Set constants\n",
    "pi = tf.constant(np.pi, dtype=DTYPE)\n",
    "viscosity = .01/pi\n",
    "\n",
    "# Define initial condition\n",
    "def fun_u_0(x):\n",
    "    return -tf.sin(pi * x)\n",
    "\n",
    "# Define boundary condition\n",
    "def fun_u_b(t, x):\n",
    "    n = x.shape[0]\n",
    "    return tf.zeros((n,1), dtype=DTYPE)\n",
    "\n",
    "# Set number of data points\n",
    "N_0 = 50\n",
    "N_b = 50\n",
    "N_r = 10000\n",
    "\n",
    "# Set boundary\n",
    "tmin = 0.\n",
    "tmax = 1.\n",
    "xmin = -1.\n",
    "xmax = 1.\n",
    "\n",
    "# Lower bounds\n",
    "lb = tf.constant([tmin, xmin], dtype=DTYPE)\n",
    "# Upper bounds\n",
    "ub = tf.constant([tmax, xmax], dtype=DTYPE)\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Draw uniform sample points for initial boundary data\n",
    "t_0 = tf.ones((N_0,1), dtype=DTYPE)*lb[0]\n",
    "x_0 = tf.random.uniform((N_0,1), lb[1], ub[1], dtype=DTYPE)\n",
    "X_0 = tf.concat([t_0, x_0], axis=1)\n",
    "\n",
    "# Evaluate intitial condition at x_0\n",
    "u_0 = fun_u_0(x_0)\n",
    "\n",
    "# Boundary data\n",
    "t_b = tf.random.uniform((N_b,1), lb[0], ub[0], dtype=DTYPE)\n",
    "x_b = lb[1] + (ub[1] - lb[1]) * tf.keras.backend.random_bernoulli((N_b,1), 0.5, dtype=DTYPE)\n",
    "X_b = tf.concat([t_b, x_b], axis=1)\n",
    "\n",
    "# Evaluate boundary condition at (t_b,x_b)\n",
    "u_b = fun_u_b(t_b, x_b)\n",
    "\n",
    "# Draw uniformly sampled collocation points\n",
    "t_r = tf.random.uniform((N_r,1), lb[0], ub[0], dtype=DTYPE)\n",
    "x_r = tf.random.uniform((N_r,1), lb[1], ub[1], dtype=DTYPE)\n",
    "X_r = tf.concat([t_r, x_r], axis=1)\n",
    "\n",
    "# Collect boundary and inital data in lists\n",
    "X_data = [X_0, X_b]\n",
    "u_data = [u_0, u_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab99a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "plt.scatter(t_0, x_0, c=u_0, marker='X', vmin=-1, vmax=1)\n",
    "plt.scatter(t_b, x_b, c=u_b, marker='X', vmin=-1, vmax=1)\n",
    "plt.scatter(t_r, x_r, c='r', marker='.', alpha=0.1)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$x$')\n",
    "\n",
    "plt.title('Positions of collocation points and boundary data');\n",
    "#plt.savefig('Xdata_Burgers.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0236b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "It 00000: loss = 7.06118882e-01\n",
      "It 00050: loss = 1.36683762e-01\n",
      "It 00100: loss = 9.49449763e-02\n",
      "It 00150: loss = 9.96587500e-02\n",
      "It 00200: loss = 7.60689601e-02\n",
      "It 00250: loss = 7.69695118e-02\n",
      "It 00300: loss = 3.55850071e-01\n",
      "It 00350: loss = 2.13368326e-01\n",
      "It 00400: loss = 1.75435930e-01\n",
      "It 00450: loss = 2.98482299e-01\n",
      "It 00500: loss = 9.11285430e-02\n",
      "It 00550: loss = 7.94845521e-02\n",
      "It 00600: loss = 1.66296855e-01\n",
      "It 00650: loss = 9.32915211e-02\n",
      "It 00700: loss = 6.93048239e-02\n",
      "It 00750: loss = 5.78584298e-02\n",
      "It 00800: loss = 1.03344902e-01\n",
      "It 00850: loss = 7.25545362e-02\n",
      "It 00900: loss = 5.34903370e-02\n",
      "It 00950: loss = 1.09374397e-01\n",
      "It 01000: loss = 7.11332262e-02\n",
      "It 01050: loss = 6.87845871e-02\n",
      "It 01100: loss = 6.65226355e-02\n",
      "It 01150: loss = 6.36751354e-02\n",
      "It 01200: loss = 6.01311252e-02\n",
      "It 01250: loss = 5.67542315e-02\n",
      "It 01300: loss = 5.31843230e-02\n",
      "It 01350: loss = 4.88201082e-02\n",
      "It 01400: loss = 4.42087054e-02\n",
      "It 01450: loss = 3.96971405e-02\n",
      "It 01500: loss = 3.53766792e-02\n",
      "It 01550: loss = 3.07660606e-02\n",
      "It 01600: loss = 2.62469184e-02\n",
      "It 01650: loss = 2.25478467e-02\n",
      "It 01700: loss = 1.94343366e-02\n",
      "It 01750: loss = 1.66758355e-02\n",
      "It 01800: loss = 1.41116418e-02\n",
      "It 01850: loss = 1.19949570e-02\n",
      "It 01900: loss = 1.04383854e-02\n",
      "It 01950: loss = 9.04162601e-03\n",
      "It 02000: loss = 7.73603236e-03\n",
      "It 02050: loss = 6.68507721e-03\n",
      "It 02100: loss = 5.98135078e-03\n",
      "It 02150: loss = 5.25242882e-03\n",
      "It 02200: loss = 4.70181275e-03\n",
      "It 02250: loss = 4.40084701e-03\n",
      "It 02300: loss = 3.92528670e-03\n",
      "It 02350: loss = 3.61911766e-03\n",
      "It 02400: loss = 3.35212657e-03\n",
      "It 02450: loss = 6.17722049e-03\n",
      "It 02500: loss = 2.93969037e-03\n",
      "It 02550: loss = 2.75930902e-03\n",
      "It 02600: loss = 2.60751578e-03\n",
      "It 02650: loss = 2.52616452e-03\n",
      "It 02700: loss = 2.34770915e-03\n",
      "It 02750: loss = 2.35828501e-03\n",
      "It 02800: loss = 2.53710942e-03\n",
      "It 02850: loss = 2.04999698e-03\n",
      "It 02900: loss = 2.26422097e-03\n",
      "It 02950: loss = 2.01305561e-03\n",
      "It 03000: loss = 1.95044954e-03\n",
      "It 03050: loss = 1.78165326e-03\n",
      "It 03100: loss = 1.74681784e-03\n",
      "It 03150: loss = 1.71322771e-03\n",
      "It 03200: loss = 1.68029743e-03\n",
      "It 03250: loss = 1.64796412e-03\n",
      "It 03300: loss = 1.61621184e-03\n",
      "It 03350: loss = 1.58499519e-03\n",
      "It 03400: loss = 1.55430555e-03\n",
      "It 03450: loss = 1.52408984e-03\n",
      "It 03500: loss = 1.49429915e-03\n",
      "It 03550: loss = 1.46483723e-03\n",
      "It 03600: loss = 1.43550895e-03\n",
      "It 03650: loss = 1.40576216e-03\n",
      "It 03700: loss = 1.37169275e-03\n",
      "It 03750: loss = 1.25699269e-03\n",
      "It 03800: loss = 1.19498943e-03\n",
      "It 03850: loss = 1.15765061e-03\n",
      "It 03900: loss = 1.12473289e-03\n",
      "It 03950: loss = 1.09261973e-03\n",
      "It 04000: loss = 1.05509919e-03\n",
      "\n",
      "Computation time: 201.7974042892456 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# Initialize model\n",
    "model = PINN_NeuralNet(lb, ub)\n",
    "model.build(input_shape=(None,2))\n",
    "\n",
    "# Initilize PINN solver\n",
    "solver = PINNSolver(model, X_r)\n",
    "\n",
    "# Decide which optimizer should be used\n",
    "mode = 'TFoptimizer'\n",
    "\n",
    "# Start timer\n",
    "t0 = time()\n",
    "\n",
    "# Choose optimizer\n",
    "lr = tf.keras.optimizers.schedules.PiecewiseConstantDecay([1000,3000],[1e-2,1e-3,5e-4])\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "solver.solve_with_TFoptimizer(optim, X_data, u_data, N=4001)\n",
    "    \n",
    "# Print computation time\n",
    "print('\\nComputation time: {} seconds'.format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.plot_solution();\n",
    "solver.plot_loss_history();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d216954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
